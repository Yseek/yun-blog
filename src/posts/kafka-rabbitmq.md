---
title: 'Kafka vs. RabbitMQ, 어떤 기술을 선택할까?'
date: '2025-07-09 17:13'
tags: ['Kafka', 'RabbitMQ', 'Message Queue', '설계']
---

![](../images/kafka-rabbitmq/kafka-rabbitmq.png)

어떤 기술을 선택할 때, 단순히 스펙을 비교하는 것보다 '문제를 해결할 수 있는가?'라는 관점에서 접근하는 것이 훨씬 중요하다. 이 글은 재직중인 회사 시스템의 문제를 해결하는 과정에서 시작되었다.

운영하는 보고 시스템이 평소에는 요청이 많지 않아 **동기(Synchronous)** 방식임에도 사용자가 큰 불편을 느끼지 못했다. 하지만, 문제는 **특정 보고 기간에 요청이 한꺼번에 몰릴 때** 발생했다. 이 '피크 타임'의 부하를 안정적으로 처리하고 사용자 경험을 해치지 않는 것이 최우선 과제였다. 

이를 해결하기 위해 **비동기(Asynchronous)** 처리 방식과 **메시지 큐(Message Queue)** 도입을 고민하는 과정에서 기술 스택이 `Kafka`와 `RabbitMQ`로 좁혀졌다. 이 포스팅은 이 이슈를 가장 잘 해결해 줄 적절한 기술을 찾기 위해 비교한 내용을 정리한 것이다.

## Kafka와 RabbitMQ, 근본적인 차이

두 기술은 단순히 성능 차이를 넘어 근본적인 아키텍처와 철학에서부터 차이가 난다.

* **RabbitMQ**: 전통적인 메시지 브로커(Message Broker)의 역할을 충실히 수행한다. AMQP(Advanced Message Queuing Protocol)와 같은 프로토콜을 구현한 브로커가 중심이 되어, 생산자(Producer)로부터 메시지를 받아 다양한 라우팅 규칙에 따라 소비자(Consumer)에게 안정적으로 '전달'하는 것에 초점을 맞춘다. 메시지가 소비자에게 성공적으로 전달되고 확인(ACK)되면 큐에서 삭제되는, 소유와 책임이 명확한 구조다.

* **Kafka**: 분산 이벤트 스트리밍 플랫폼(Distributed Event Streaming Platform)으로 정의된다. 메시지를 '전달'하고 삭제하는 개념이 아닌, 데이터를 변경 불가능한 로그(Immutable Log)의 형태로 계속해서 쌓아 나가는 구조다. 브로커는 데이터의 저장소 역할을 하고, 소비자는 자신이 필요한 데이터를 직접 가져와(Pull) 처리한다. 데이터는 삭제되지 않고 설정된 기간 동안 보존되므로, 이벤트 스트림을 여러 번 다시 읽는 등의 활용이 가능하다.

## 해결 과제에 기반한 비교 분석

보고 시스템의 부하 문제를 해결하기 위해, 다음과 같은 기준을 가지고 두 기술을 비교했다.

### 1. 대용량 트래픽 처리 능력

가장 중요한 평가 기준이었다. 특정 기간에 몰리는 대량의 요청을 막힘없이 받아낼 수 있어야 했다.

* **RabbitMQ**: 잘 튜닝된 환경에서 초당 수만 건의 메시지를 처리할 수 있다. 대부분의 마이크로서비스 환경에서 요구하는 수준을 충분히 만족시킨다. 하지만 브로커의 역할이 복잡하고 메시지 단위의 처리가 많아, 극단적인 수준의 처리량이 요구될 때는 성능 한계에 부딪힐 수 있다.

* **Kafka**: 설계 자체가 대규모 데이터 처리에 맞춰져 있다. 디스크에 순차적으로 I/O를 수행하고, 파티션(Partition)을 통해 병렬 처리를 극대화하는 방식으로 초당 수십만에서 수백만 건의 메시지를 처리할 수 있다. 대규모 로그 수집, 실시간 분석 파이프라인 등에서 Kafka가 표준처럼 사용되는 이유이다.

**판단**: 순간적인 요청 폭증을 안정적으로 버퍼링하고 처리하기 위해서는, 더 높은 처리량을 보장하는 **Kafka**가 더 적합한 해결책이라고 본다.

### 2. 데이터 보관 및 소비의 유연성

전송된 보고서 생성 요청이 유실되지 않고, 장애 상황에서 재처리가 가능한지도 중요한 요건이었다.

* **RabbitMQ**: 메시지는 소비자가 성공적으로 처리했다고 응답(ACK)하는 즉시 큐에서 제거된다. 이는 작업을 한 번만 처리해야 하는 'Task Queue'에 매우 적합한 방식이다.

* **Kafka**: 메시지를 소비해도 데이터가 삭제되지 않는다. 설정된 보관 주기(retention period)에 따라 데이터를 디스크에 유지한다. 이 덕분에 소비자에 장애가 발생해도, 마지막으로 처리했던 위치(Offset)부터 다시 작업을 이어갈 수 있다. 또한, 동일한 데이터를 여러 다른 목적을 가진 소비자들이 각자의 필요에 따라 여러 번 읽어갈 수 있다는 장점이 있다.

**판단**: 장애 발생 시 데이터 유실 없이 안전하게 재처리할 수 있는 가능성을 열어두는 **Kafka**의 데이터 보존 정책이 우리 시스템의 안정성을 높이는 데 더 유리하다고 판단했다.

### 3. 데이터 재활용 및 분석 가능성

지금 당장은 요청을 안정적으로 처리하는 것이 급선무지만, 장기적인 관점에서 이 요청 데이터들은 그 자체로 귀중한 자산이 될 수 있다. 예를 들어, '어떤 시간대에 요청이 몰리는지', '어떤 종류의 보고가 집중적으로 생성되는지' 등을 분석하면 시스템 최적화나 비즈니스 인사이트를 얻을 수 있다.

* **RabbitMQ**: 메시지가 소비자에게 성공적으로 전달되고 나면 큐에서 영구적으로 삭제된다. 데이터를 분석하려면 소비자가 메시지를 처리할 때 별도의 데이터베이스나 로그 시스템에 다시 저장해야만 한다. 즉, 데이터 분석을 위해서는 추가적인 아키텍처 설계가 반드시 필요하다.

* **Kafka**: 메시지(이벤트)를 소비한 후에도 설정된 기간 동안 데이터를 그대로 보존한다. 이 '변경 불가능한 로그(Immutable Log)'는 그 자체로 하나의 데이터베이스처럼 작동한다. 덕분에 우리는 언제든지 과거의 요청 기록을 다시 꺼내볼 수 있다. 실시간으로 요청을 처리하는 소비자 외에, 데이터 분석을 위한 또 다른 소비자를 붙여서 자유롭게 데이터를 분석하고 활용하는 것이 가능하다.

**판단**: 당장의 문제 해결을 넘어, 추후 데이터 활용 가능성을 열어두는 것은 매우 중요한 가치다. Kafka는 데이터를 일회성으로 '소비'하고 버리는 것이 아니라, '자산'으로 보존하고 재활용할 수 있는 구조를 제공한다. 이는 향후 시스템 운영을 고도화하고 데이터 기반의 의사결정을 내리는 데 있어 RabbitMQ가 제공할 수 없는 강력한 장점이라고 판단했다.

## 최종 결론

RabbitMQ는 복잡한 라우팅과 유연한 메시지 처리가 필요할 때 매우 강력한 도구다. 하지만 '특정 기간에 집중되는 대용량 요청을 안정적으로 처리'하는 나의 구체적인 문제를 해결하기 위한 최적의 선택은 **Kafka**였다.

* **압도적인 처리량으로 피크 타임의 부하를 안정적으로 수용**
* **데이터 보존을 통한 장애 복구 및 데이터 재처리 능력**
* **데이터 재활용 및 분석 가능성(미래 확장성)**

위와 같은 이유로 Kafka 도입을 결정했다. 이 과정은 결국 기술의 우열을 가리는 것이 아니라, 주어진 문제와 상황에 가장 적합한 도구를 찾는 과정이라는 것을 다시금 확인하는 계기가 되었다.

## 참고
- https://www.confluent.io/learn/rabbitmq-vs-apache-kafka/#performance-benchmarking-comparison-rabbitmq-vs-kafka